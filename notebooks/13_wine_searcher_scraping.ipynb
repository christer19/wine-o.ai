{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import requests\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.common.desired_capabilities import DesiredCapabilities\n",
    "\n",
    "from fake_useragent import UserAgent\n",
    "import multiprocess as mp\n",
    "\n",
    "from glob import glob\n",
    "\n",
    "import dill\n",
    "import re\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A function to create the Selenium web driver\n",
    "\n",
    "def make_driver(port):\n",
    "    \n",
    "    service_args = ['--proxy=127.0.0.1:{}'.format(port), '--proxy-type=socks5']\n",
    "    \n",
    "    dcap = dict(DesiredCapabilities.PHANTOMJS)\n",
    "    ua = UserAgent()\n",
    "    dcap.update({'phantomjs.page.settings.userAgent':ua.random})\n",
    "    \n",
    "    phantom_path = '/usr/bin/phantomjs'\n",
    "    \n",
    "    driver = webdriver.PhantomJS(phantom_path, \n",
    "                                   desired_capabilities=dcap,\n",
    "                                   service_args=service_args)\n",
    "    \n",
    "    return driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ncomputers = 16\n",
    "nthreads = 16\n",
    "\n",
    "port_nos = np.array([8081+x for x in range(ncomputers)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Start the ssh tunnels\n",
    "! ./ssh_tunnels.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrape the catalog of producers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def scrape_catalog(args):\n",
    "    port, page_nums = args\n",
    "\n",
    "    base_url = 'http://www.wine-searcher.com/biz/producers?s={}'\n",
    "    \n",
    "    driver = make_driver(port)\n",
    "\n",
    "    table_list = list()\n",
    "    for num in page_nums:\n",
    "        print num\n",
    "        \n",
    "        full_url = base_url.format(num * 25 + 1)\n",
    "\n",
    "        driver.get(full_url)\n",
    "        time.sleep(10. + np.random.random()*5)\n",
    "        html = driver.page_source\n",
    "        soup = BeautifulSoup(html, 'lxml')\n",
    "        \n",
    "        try:\n",
    "            table = pd.read_html(html)[2]\n",
    "            columns = table.iloc[0].values\n",
    "            columns[2] = 'Wines'\n",
    "            table = table.iloc[1:25]\n",
    "            table.columns = columns\n",
    "\n",
    "            url_list = [x.find('a').get('href') for x in soup.find_all(attrs={'class':'wlrwdt wlbdrl vtop'})]\n",
    "            table['Url'] = url_list\n",
    "            table['Page'] = num\n",
    "\n",
    "            winery_urls = list()\n",
    "            for url in url_list:\n",
    "                try:\n",
    "                    driver.get(url)\n",
    "                    time.sleep(10. + np.random.random()*5)\n",
    "                    html = driver.page_source\n",
    "                    soup = BeautifulSoup(html, 'lxml')\n",
    "\n",
    "                    winery_urls.append(soup.find(text=re.compile('Winery Profile')).find_parent().get('href'))\n",
    "                except:\n",
    "                    winery_urls.append('')\n",
    "\n",
    "            table['Winery Url'] = winery_urls\n",
    "\n",
    "            table.to_pickle('../pkl/13_wine_searcher_scraping_table_{}.pkl'.format(num))\n",
    "\n",
    "            table_list.append(table)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "    return table_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([80])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the completed data\n",
    "\n",
    "num_list = np.arange(0,1742)\n",
    "\n",
    "file_list = glob('../pkl/13_wine_searcher_scraping_table_*.pkl')\n",
    "int_sorter = lambda x: int(re.search(r\"\"\"_([0-9]+)\\.pkl\"\"\", x).group(1))\n",
    "file_nums = sorted(np.array(map(int_sorter, file_list)))\n",
    "\n",
    "num_list = num_list[np.invert(np.in1d(num_list, file_nums))]\n",
    "\n",
    "num_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(num_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80\n"
     ]
    }
   ],
   "source": [
    "used_threads = np.min([nthreads, len(num_list)])\n",
    "\n",
    "used_port_nos = port_nos\n",
    "if used_threads < nthreads:\n",
    "    used_port_nos = port_nos[:used_threads]\n",
    "    \n",
    "pool = mp.Pool(processes=used_threads)\n",
    "table_list = pool.map(scrape_catalog, [x for x in zip(used_port_nos, \n",
    "                                                     np.array_split(num_list, used_threads))])\n",
    "pool.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "table_df = pd.concat(sum(table_list,[]), axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "table_df.to_pickle('../pkl/13_wine_searcher_url_table.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the data from wineries with images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get images from profile\n",
    "driver.get(winery_url)\n",
    "html = driver.page_source\n",
    "soup = BeautifulSoup(html, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_images = int(soup.find(attrs={'id':'img_high_t'}).text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# iterate through each image, find \"view larger\" and download if it exists\n",
    "\n",
    "pos = 1\n",
    "for _ in range(num_images - 1):\n",
    "    \n",
    "    try:\n",
    "        driver.find_element_by_id('showFullLabel1').click()\n",
    "        html = driver.page_source\n",
    "        soup = BeautifulSoup(html, 'lxml')\n",
    "        \n",
    "        wine_info = soup.find(attrs={'id':'imgLabel'})\n",
    "        wine_name = wine_info.get('alt')\n",
    "        wine_url = wine_info.get('src')\n",
    "        wine_height = wine_info.get('height')\n",
    "        wine_width = wine_info.get('width')\n",
    "        \n",
    "        img = req.get(wine_url)#, proxies=req_proxy)\n",
    "        time.sleep(1.2)\n",
    "\n",
    "        filext = os.path.splitext(wine_url)[-1]\n",
    "        path = 'tmp_' + str(pos) + '.' + filext\n",
    "\n",
    "        if img.status_code == 200:\n",
    "            with open(path, 'wb') as f:\n",
    "                for chunk in img:\n",
    "                    f.write(chunk)\n",
    "                    \n",
    "        driver.find_element_by_id('okButtonModal').click()\n",
    "    except:\n",
    "        pass\n",
    "                    \n",
    "    pos += 1\n",
    "    driver.find_element_by_id('nextImg').click()\n",
    "        \n",
    "        \n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
